{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b4c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SamProcessor, SamModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from segment_anything import SamProcessor\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, processor):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.processor = processor\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        image = Image.open(os.path.join(self.image_dir, image_file)).convert(\"RGB\")\n",
    "        mask_path = os.path.join(self.mask_dir, image_file)\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Warning: Mask file for {image_file} not found, skipping this image.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "        mask = Image.open(mask_path).convert(\"L\") \n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        mask = torch.tensor(np.array(mask), dtype=torch.long)\n",
    "\n",
    "        return inputs, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_dir = \"E:/sam-vit-data-all/Exclusive-multicolor\"\n",
    "train_image_dir = \"E:/sam-vit-data-all/converted_images\"\n",
    "test_mask_dir = \"E:/sam-vit-data-all/Exclusive-multicolor_test\"\n",
    "test_image_dir = \"E:/sam-vit-data-all/converted_images_test\"\n",
    "\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "train_dataset = SegmentationDataset(train_image_dir, train_mask_dir, processor)\n",
    "test_dataset = SegmentationDataset(test_image_dir, test_mask_dir, processor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2318d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(preds, targets, smooth=1e-6):\n",
    "    preds = preds.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "    intersection = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum()\n",
    "    dice_coefficient = (2. * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")  \n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc702a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (inputs, masks) in enumerate(train_loader):\n",
    "        inputs = {key: val.squeeze().to(device) for key, val in inputs.items()}\n",
    "        masks = masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        predicted_masks = outputs.masks \n",
    "        preds = predicted_masks.argmax(dim=1)\n",
    "        loss = criterion(preds, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca72098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_pixels = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in test_loader:\n",
    "            inputs = {key: val.squeeze().to(device) for key, val in inputs.items()}\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(**inputs)\n",
    "            predicted_masks = outputs.masks  \n",
    "            preds = predicted_masks.argmax(dim=1)\n",
    "            total_correct += (preds == masks).sum().item()\n",
    "            total_pixels += masks.numel()\n",
    "    accuracy = total_correct / total_pixels\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecaef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    test_accuracy = evaluate(model, test_loader, device)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"model_epoch_{epoch + 1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "image_path = \"E:/image.jpg\" \n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "predicted_mask = logits.argmax(dim=1).squeeze().cpu().numpy()\n",
    "import numpy as np\n",
    "def colorize_mask(mask):\n",
    "    colors = np.array([\n",
    "        [0, 0, 0],        \n",
    "        [255, 0, 0],      \n",
    "        [0, 255, 0],      \n",
    "        [0, 0, 255],      \n",
    "        [255, 255, 0],    \n",
    "        [255, 0, 255],    \n",
    "        [0, 255, 255],    \n",
    "        # Light colors\n",
    "        [255, 182, 193],  \n",
    "        [255, 228, 196],  \n",
    "        [255, 240, 245],  \n",
    "        [255, 222, 173],  \n",
    "        [255, 255, 224],  \n",
    "        [216, 191, 216],  \n",
    "        [255, 240, 245],  \n",
    "        [255, 239, 196],   \n",
    "        [219, 112, 147],  \n",
    "        [176, 224, 230],  \n",
    "        [255, 250, 205], \n",
    "        [152, 251, 152],  \n",
    "        [144, 238, 144],  \n",
    "        [173, 216, 230],  \n",
    "        [255, 182, 193],  \n",
    "        [240, 128, 128],  \n",
    "        [240, 230, 140],  \n",
    "        [250, 250, 210],  \n",
    "        [253, 253, 150],  \n",
    "        [236, 240, 252],  \n",
    "        [255, 228, 225],  \n",
    "        [255, 218, 185],  \n",
    "        [245, 245, 220],  \n",
    "        [255, 218, 185],  \n",
    "        [255, 248, 220],  \n",
    "        [255, 228, 181],  \n",
    "        [240, 230, 140],  \n",
    "        [255, 241, 199],  \n",
    "        [237, 249, 255],  \n",
    "        [216, 191, 216],  \n",
    "    ])\n",
    "    \n",
    "    return colors\n",
    "    color_mask = colors[mask]\n",
    "    return color_mask\n",
    "\n",
    "colored_mask = colorize_mask(predicted_mask)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(colored_mask)\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
