{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a092ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3-class U-Net training with 3-color masks\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f583f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = sorted(glob.glob(\"K:/images/*\"))\n",
    "label_list = sorted(glob.glob(\"K:/masks/*\"))\n",
    "\n",
    "image_size = (512, 512)\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "\n",
    "background = [255, 0, 0]\n",
    "boundary = [0, 255, 0]\n",
    "inside = [0, 0, 255]\n",
    "COLOR_DICT = np.array([background, boundary, inside])\n",
    "num_class = 3\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(30,10))\n",
    "sampling = random.sample(range(len(image_list)), k=5)\n",
    "for col, i in enumerate(sampling):\n",
    "    img = cv2.cvtColor(cv2.imread(image_list[i]), cv2.COLOR_BGR2RGB)\n",
    "    label = cv2.cvtColor(cv2.imread(label_list[i]), cv2.COLOR_BGR2RGB)\n",
    "    axs[0, col].imshow(img)\n",
    "    axs[0, col].axis('off')\n",
    "    axs[0, col].set_title(f\"Image {col+1}\")\n",
    "    axs[1, col].imshow(label)\n",
    "    axs[1, col].axis('off')\n",
    "    axs[1, col].set_title(f\"Mask {col+1}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87655905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_onehot(mask, color_dict=COLOR_DICT, tol=10):\n",
    "    h, w, _ = mask.shape\n",
    "    onehot = np.zeros((h, w, len(color_dict)), dtype=np.uint8)\n",
    "    for i, color in enumerate(color_dict):\n",
    "        matches = np.all(np.abs(mask - color) <= tol, axis=-1)\n",
    "        onehot[..., i] = matches.astype(np.uint8)\n",
    "    return onehot\n",
    "\n",
    "def adjustData(img, mask, target_size):\n",
    "    img = np.array([cv2.resize(im, target_size) for im in img]) / 255.0\n",
    "    mask_resized = np.array([cv2.resize(mk, target_size, interpolation=cv2.INTER_NEAREST) for mk in mask])\n",
    "    onehot_masks = np.array([mask_to_onehot(mk) for mk in mask_resized])\n",
    "    return img, onehot_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size, image_list, mask_list, augment_dict=None, target_size=image_size):\n",
    "    datagen_args = augment_dict if augment_dict else {}\n",
    "    image_datagen = ImageDataGenerator(**datagen_args)\n",
    "    mask_datagen = ImageDataGenerator(**datagen_args)\n",
    "\n",
    "    while True:\n",
    "        idxs = np.random.permutation(len(image_list))\n",
    "        for i in range(0, len(image_list), batch_size):\n",
    "            batch_idxs = idxs[i:i+batch_size]\n",
    "            batch_images = [cv2.cvtColor(cv2.imread(image_list[j]), cv2.COLOR_BGR2RGB) for j in batch_idxs]\n",
    "            batch_masks = [cv2.cvtColor(cv2.imread(mask_list[j]), cv2.COLOR_BGR2RGB) for j in batch_idxs]\n",
    "            if augment_dict:\n",
    "                seed = np.random.randint(0, 10000)\n",
    "                batch_images = next(image_datagen.flow(np.array(batch_images), batch_size=batch_size, seed=seed))\n",
    "                batch_masks = next(mask_datagen.flow(np.array(batch_masks), batch_size=batch_size, seed=seed))\n",
    "            X, Y = adjustData(batch_images, batch_masks, target_size)\n",
    "            yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673880fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net model\n",
    "def conv_bn(filters, x):\n",
    "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(512, 512, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    c1 = conv_bn(64, inputs)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "    c2 = conv_bn(128, p1)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "    c3 = conv_bn(256, p2)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "    c4 = conv_bn(512, p3)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "\n",
    "    c5 = conv_bn(1024, p4)\n",
    "\n",
    "    u6 = UpSampling2D((2,2))(c5)\n",
    "    u6 = Conv2D(512, 2, activation='relu', padding='same')(u6)\n",
    "    merge6 = concatenate([c4, u6])\n",
    "    c6 = conv_bn(512, merge6)\n",
    "\n",
    "    u7 = UpSampling2D((2,2))(c6)\n",
    "    u7 = Conv2D(256, 2, activation='relu', padding='same')(u7)\n",
    "    merge7 = concatenate([c3, u7])\n",
    "    c7 = conv_bn(256, merge7)\n",
    "\n",
    "    u8 = UpSampling2D((2,2))(c7)\n",
    "    u8 = Conv2D(128, 2, activation='relu', padding='same')(u8)\n",
    "    merge8 = concatenate([c2, u8])\n",
    "    c8 = conv_bn(128, merge8)\n",
    "\n",
    "    u9 = UpSampling2D((2,2))(c8)\n",
    "    u9 = Conv2D(64, 2, activation='relu', padding='same')(u9)\n",
    "    merge9 = concatenate([c1, u9])\n",
    "    c9 = conv_bn(64, merge9)\n",
    "\n",
    "    outputs = Conv2D(num_class, 1, activation='softmax')(c9)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ee0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_args = dict(horizontal_flip=True, vertical_flip=True)\n",
    "val_gen_args = dict(horizontal_flip=False, vertical_flip=False)\n",
    "\n",
    "split_idx = int(0.8*len(image_list))\n",
    "train_images = image_list[:split_idx]\n",
    "train_masks = label_list[:split_idx]\n",
    "val_images = image_list[split_idx:]\n",
    "val_masks = label_list[split_idx:]\n",
    "\n",
    "trainGene = trainGenerator(batch_size, train_images, train_masks, augment_dict=train_gen_args)\n",
    "valGene = trainGenerator(batch_size, val_images, val_masks, augment_dict=val_gen_args)\n",
    "\n",
    "model = unet(input_size=(image_size[0], image_size[1], 3))\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9abfe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_images)//batch_size\n",
    "validation_steps = len(val_images)//batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint('unet_best.h5', monitor='loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    trainGene,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valGene,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70063336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d10f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_img_dir = \"/content/images-in\"\n",
    "test_mask_dir = \"/content/testMask\"  \n",
    "save_pred_dir = \"test_predictions1\"\n",
    "os.makedirs(save_pred_dir, exist_ok=True)\n",
    "\n",
    "test_images = sorted(glob.glob(os.path.join(test_img_dir, \"*\")))\n",
    "test_masks = sorted(glob.glob(os.path.join(test_mask_dir, \"*\"))) if os.path.exists(test_mask_dir) else None\n",
    "\n",
    "def preprocess_test_image(img_path):\n",
    "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def onehot_to_color(pred_mask, color_dict=COLOR_DICT):\n",
    "    mask_class = np.argmax(pred_mask, axis=-1)\n",
    "    h, w = mask_class.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for i, color in enumerate(color_dict):\n",
    "        color_mask[mask_class == i] = color\n",
    "    return color_mask\n",
    "\n",
    "for i, img_path in enumerate(test_images):\n",
    "    img_name = os.path.basename(img_path)\n",
    "\n",
    "    img = preprocess_test_image(img_path)\n",
    "    pred = model.predict(np.expand_dims(img, 0))[0]\n",
    "    pred_color = onehot_to_color(pred)\n",
    "\n",
    "    save_path = os.path.join(save_pred_dir, img_name)\n",
    "    cv2.imwrite(save_path, cv2.cvtColor(pred_color, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    if test_masks:\n",
    "        mask_path = test_masks[i]\n",
    "        true_mask = cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_BGR2RGB)\n",
    "        true_mask = cv2.resize(true_mask, image_size)\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow((img * 255).astype(np.uint8))\n",
    "    plt.title(\"Image\")\n",
    "    plt.axis(\"off\")\n",
    " \n",
    "    if test_masks:\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(true_mask)\n",
    "        plt.title(\"Ground Truth Mask\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(pred_color)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "     # ----- IoU -----\n",
    "    if test_masks:\n",
    "        true_onehot = mask_to_onehot(true_mask)\n",
    "        pred_onehot = mask_to_onehot(pred_color)\n",
    "\n",
    "        y_true = np.argmax(true_onehot, axis=-1).flatten()\n",
    "        y_pred = np.argmax(pred_onehot, axis=-1).flatten()\n",
    "\n",
    "        iou = jaccard_score(y_true, y_pred, average='macro')\n",
    "        print(f\"{img_name} - IoU: {iou:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
